# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vbjf_X8CModuu7s1Y_QX3A5IWPcE-rtA
"""

!pip install streamlit pyngrok transformers beautifulsoup4 requests

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import requests
# from bs4 import BeautifulSoup
# from transformers import pipeline
# 
# st.title("Professional Website URL Summarizer")
# 
# # Load model
# @st.cache_resource
# def load_model():
#     return pipeline("text2text-generation", model="facebook/bart-large-cnn")
# 
# summarizer = load_model()
# 
# # Extract main article text
# def extract_text(url):
#     response = requests.get(url)
#     soup = BeautifulSoup(response.text, "html.parser")
# 
#     article = soup.find("article")
# 
#     if article:
#         paragraphs = article.find_all("p")
#     else:
#         paragraphs = soup.find_all("p")
# 
#     text = " ".join([p.get_text() for p in paragraphs])
#     return text
# 
# 
# # Chunk summarization
# def summarize_long_text(text):
#     max_chunk = 1000
#     chunks = [text[i:i+max_chunk] for i in range(0, len(text), max_chunk)]
# 
#     summaries = []
# 
#     for chunk in chunks:
#         summary = summarizer(chunk, max_length=120, min_length=40, do_sample=False)
#         summaries.append(summary[0]["summary_text"])
# 
#     final_summary = " ".join(summaries)
#     return final_summary
# 
# 
# url = st.text_input("Enter website URL")
# 
# if st.button("Summarize"):
#     if url == "":
#         st.warning("Enter a valid URL")
#     else:
#         with st.spinner("Extracting article..."):
#             article = extract_text(url)
# 
#         if len(article) == 0:
#             st.error("No content extracted")
#         else:
#             with st.spinner("Generating summary..."):
#                 final_summary = summarize_long_text(article)
# 
#             st.subheader("Summary")
#             st.write(final_summary)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# streamlit
# requests
# beautifulsoup4
# transformers
# torch
# sentencepiece

!jupyter nbconvert --to script
app.ipynb

from pyngrok import ngrok
public_url = ngrok.connect(8501)
print(public_url)

!streamlit run app.py &

!pip install ngrok

from pyngrok import ngrok
ngrok.set_auth_token("394OEVQ0vgAZ9tUu1689he5dqw3_2JxGQu2oHXJyei9V54Sxk")

!pip install pyngrok

!pip uninstall -y transformers accelerate tokenizers huggingface_hub sentencepiece
!pip install -U transformers accelerate tokenizers huggingface_hub sentencepiece

from transformers import pipeline

summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

print(summarizer("Artificial intelligence is transforming the world.", max_length=30))

from transformers import pipeline

summarizer = pipeline(
    model="facebook/bart-large-cnn"
)

from transformers import pipeline

summarizer = pipeline(task="summarization",
    model="facebook/bart-large-cnn"
)

text = "Artificial Intelligence is transforming industries worldwide by automating complex tasks."

print(summarizer(text, max_length=50, min_length=10))

!pip install "transformers<5" -U

from huggingface_hub import login
login()

import transformers
print(transformers.__version__)

!pip uninstall -y transformers tokenizers accelerate huggingface_hub sentencepiece
!pip install transformers==4.35.2 tokenizers==0.14.1 accelerate huggingface_hub sentencepiece

!pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install transformers==4.35.2 sentencepiece accelerate huggingface_hub streamlit

pip install transformers==4.41.2

pip install --upgrade sentence-transformers

!pip uninstall transformers -y
!pip install transformers sentence-transformers

!pip show transformers
!pip show sentence-transformers

from sentence_transformers import SentenceTransformer
model = SentenceTransformer("all-MiniLM-L6-v2")
print("Model loaded successfully")